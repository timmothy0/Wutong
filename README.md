This is my first time joining in data mining competition, I wanna record what I have learned from this competition and share my experience.
Knowledge learned during this competition as following:
1.better understanding about lgm parameters
2.how to deal with unbalanced data
3.adjusting threshold works!
4.stacking feature learned from kaggle
5.how to use pseudo-labelling

I did many feature engineering, but most of them do work on my model. 
I did not adjust threshold.
I just use single model lgm, so the variance between local result and online result was so high.
Limited by time,I did not try stacking in the end.
Many ideas about feature engineering not realized.
<!---
timmothy0/timmothy0 is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
